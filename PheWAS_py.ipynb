{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phenome-Wide analysis on COPDgene data: python PIC-SURE API use-case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is an illustration example of how to use the python **PIC-SURE API** to select and query data from an HPDS-hosted database. It takes as use-case a simple PheWAS analysis. This notebook is intentionally straightforward, without too much explanation. For a more step-by-step introduction to the python PIC-SURE API, see the `PICSURE-API_101_PheWAS_example.ipynb` Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before running this notebook, please be sure to get an user-specific security token. For more information on how to proceed, see the `HPDS_connection.ipynb` notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System requirements\n",
    "- python 3.6 or later\n",
    "- pip & bash interpreter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation of external dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "import PicSureHpdsLib\n",
    "import PicSureClient\n",
    "\n",
    "from python_lib.utils import get_multiIndex_variablesTable, get_dic_renaming_vars, match_dummies_to_varNames, joining_variablesTable_onCol\n",
    "from python_lib.HPDS_connection_manager import tokenManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NB: This Jupyter Notebook has been written using PIC-SURE API following versions:\\n- PicSureHpdsLib: 1.1.0\\n- PicSureClient: 0.1.0\")\n",
    "print(\"The PIC-SURE API libraries versions you've been downloading are:\\n- PicSureHpdsLib: {0}\\n- PicSureClient: {1}\".format(PicSureHpdsLib.__version__, PicSureClient.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas DataFrame display options\n",
    "pd.set_option(\"max.rows\", 435)\n",
    "\n",
    "# Matplotlib display parameters\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 14\n",
    "fig_size[1] = 8\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "font = {'weight' : 'bold',\n",
    "        'size'   : 12}\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to a PIC-SURE network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PICSURE_network_URL = \"https://biodatacatalyst.integration.hms.harvard.edu/picsure\"\n",
    "resource_id = \"02e23f52-f354-4e8b-992c-d37c8b9ba140\"\n",
    "token_file = \"tokens/copd.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = tokenManager(token_file).get_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = PicSureClient.Client()\n",
    "connection = client.connect(PICSURE_network_URL, token, allowSelfSignedSSL=True)\n",
    "adapter = PicSureHpdsLib.Adapter(connection)\n",
    "resource = adapter.useResource(resource_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PheWAS analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a nutshell, this PheWAS analysis consists of two main steps:\n",
    "- Running univariate tests again every phenotypes variable\n",
    "- Adjusting for multiple testing issue\n",
    "\n",
    "In this example, we will select every phenotype variables available in the Dictionary, except for the variables pertaining to the \"Sub-study ESP LungGO COPDGene\" category (very small and specific population as compared to the COPDGene one)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PheWAS analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a nutshell, this PheWAS analysis follows those subsequent steps:\n",
    "- Retrieving the variables dictionary, using the PIC-SURE API dedicated methods\n",
    "- From the info provided by the dictionary, retrieving the data in an exploitable format through PIC-SURE API calls\n",
    "- Data management\n",
    "- Running univariate tests again every phenotypes variable\n",
    "- Adjusting for multiple testing issue\n",
    "- Plotting the results\n",
    "\n",
    "\n",
    "This analysis is conducted using COPDGene Study data. The study overall goal is to detect underlying genetic factors to develop Chronic Obstructive Pulmonary Disease (COPD), and enrolled more than 10,000 individuals ([more information on COPDGene Study](http://www.copdgene.org))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Retrieving variable dictionary from HPDS Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requesting only COPDGene related variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_variablesDict = resource.dictionary().find(\"Genetic Epidemiology of COPD (COPDGene)\").DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variablesDict = get_multiIndex_variablesTable(plain_variablesDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Selecting variables and retrieving data from HPDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_pheno = variablesDict.index.get_level_values(1) == 'Subject Phenotype'\n",
    "mask_status = variablesDict.index.get_level_values(2) == 'Affection status'\n",
    "mask_vars = mask_pheno | mask_status\n",
    "selected_vars = variablesDict.loc[mask_vars, \"varName\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PICSURE_network_URL = \"https://biodatacatalyst.integration.hms.harvard.edu/picsure\"\n",
    "resource_id = \"02e23f52-f354-4e8b-992c-d37c8b9ba140\"\n",
    "token_file = \"tokens/copd.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(selected_vars[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = resource.query()\n",
    "query.select().add(selected_vars[1])\n",
    "facts = query.getResultsDataFrame().set_index(\"Patient ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just check that our query runned the way intended by looking at the number of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{0} rows, {1} columns\".format(*facts.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data-management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting variables regarding their types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One important step in a PheWAS is to get the distinction between categorical and numerical variables. This distinction is straightforward using the variables dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_categories = variablesDict.loc[mask_vars, \"categorical\"] == True\n",
    "categorical_varnames = variablesDict.loc[mask_vars,:].loc[mask_categories, \"varName\"].tolist()\n",
    "continuous_varnames = variablesDict.loc[mask_vars,:].loc[~mask_categories, \"varName\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the dependent variable to study\n",
    "Most of PheWAS use a genetic variant as the variable used to separate the population between cases and controls. However the population doesn't have to be dichotomized using a genetic variant, and any phenotypic variable could be used to run a PheWAS analysis (see for example [*Neuraz et al.*, 2013](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003405)). \n",
    "\n",
    "Here we will use the **COPD status** as the case-control variable to dichotomize the population in our analysis (ie the dependent variable for which univariate association test will be run against)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent_var_name = variablesDict.loc[variablesDict[\"simplified_varName\"] == \"00 Affection status\", \"varName\"].values[0]\n",
    "categorical_varnames.remove(dependent_var_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we subset our population regarding the relevant values for the COPD diagnosis variable (i.e. keeping \"Case\" and \"Control\" individuals, thus discarding \"Other\", \"Control, Exclusionary Disease\", and null values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_dependent_var_name = facts[dependent_var_name].isin([\"Case\", \"Control\"])\n",
    "facts = facts.loc[mask_dependent_var_name,:]\n",
    "print(\"Control: {0} individuals\\nCase: {1} individuals\".format(*facts[dependent_var_name].value_counts().tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create dummy variables in order to be able to carry categorical univariate statistical tests, and we store their names in the dictionary alongside corresponding original variables in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "facts_dummies = pd.get_dummies(facts, columns=categorical_varnames, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_dummies_varNames = match_dummies_to_varNames(facts.columns,\n",
    "                                                      facts_dummies.columns,\n",
    "                                                      columns=[\"varName\", \"dummies_varName\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "variablesDict = joining_variablesTable_onCol(variablesDict,\n",
    "                                              matching_dummies_varNames,\n",
    "                                              left_col=\"varName\",\n",
    "                                              right_col=\"varName\",\n",
    "                                              overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variablesDict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Univariate statistical tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To this point, each variable present in the facts_dummies dataset will be tested again the selected dependent variable, (ie presence or absence of COPD). \n",
    "\n",
    "Two different association test will be carried out according to variables data types: \n",
    "- Mann-Whitney U test for continuous ones\n",
    "- Fisher exact test for categorical ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical variables: Mann-Whitney U test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = facts_dummies.groupby(dependent_var_name) \n",
    "\n",
    "dic_mannwhitneyu = {}\n",
    "for var in continuous_varnames: \n",
    "    group1, group2 = [group[1].dropna() for group in grouped[var]]\n",
    "    try:\n",
    "        dic_mannwhitneyu[var] = stats.mannwhitneyu(group1, group2).pvalue\n",
    "    except ValueError:\n",
    "        dic_mannwhitneyu[var] = np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qualitative variables: Fisher Exact test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_categorical_varnames = variablesDict.loc[variablesDict[\"varName\"].isin(categorical_varnames),:]\\\n",
    "[\"dummies_varName\"].values[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fisher test for categorical variables\n",
    "from tqdm import tqdm\n",
    "dic_fisher = {}\n",
    "try:\n",
    "    for var in tqdm(dummy_categorical_varnames, position=0, leave=True):\n",
    "        if type(var) != str:\n",
    "            print(\"skipping {0}\".format(var))\n",
    "            continue\n",
    "        elif var not in facts_dummies.columns:\n",
    "            print(\"skipping {0}, not in dataframe columns\".format(var))\n",
    "            continue        \n",
    "        crosstab = pd.crosstab(facts_dummies[var], facts_dummies[dependent_var_name])\n",
    "        if crosstab.shape == (1,2):\n",
    "            dic_fisher[var] = np.NaN\n",
    "        else:\n",
    "            dic_fisher[var] = stats.fisher_exact(crosstab)[1]\n",
    "except AttributeError:\n",
    "    print(\"End of loop tqdm AttributeError catched\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Univariate test p-values distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([v for v in dic_mannwhitneyu.values()]).plot.hist(bins=30)\n",
    "plt.suptitle(\"Distribution of individual p-values for Mann-Whintey U test\",\n",
    "             weight=\"bold\",\n",
    "            fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([v for v in dic_fisher.values()]).plot.hist(bins=20)\n",
    "plt.suptitle(\"Distribution of individual p-values for Fisher association test\", \n",
    "             size=30,\n",
    "             weight=\"bold\",\n",
    "            fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Multiple hypotheses testing correction: Bonferroni Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to handle the multiple comparison issue (increase in the probability to \"discover\" false statistical associations, because of the number of tests performed), we will use the Bonferroni correction method. Although many other multiple comparison exist, Bonferroni is the most straightforward to use, because it doesn't require assumptions about variables correlation. Other PheWAS analysis also use False Discovery Rate controlling procedures ([see](https://en.wikipedia.org/wiki/False_discovery_rate))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a nutshell, Bonferonni allows to calculate a corrected \"statistical significant threshold\" according to the number of test performed. Every p-value below this threshold will be deemed statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging pvalues from different tests\n",
    "dic_pvalues = {**dic_mannwhitneyu, **dic_fisher}\n",
    "df_pvalues = pd.DataFrame.from_dict(dic_pvalues, orient=\"index\", columns=[\"pvalues\"])\\\n",
    ".rename_axis(\"dummies_varName\")\\\n",
    ".reset_index(drop=False)\n",
    "\n",
    "# Adding pvalues results as a new column to variablesDict\n",
    "variablesDict = joining_variablesTable_onCol(variablesDict,\n",
    "                                              df_pvalues,\n",
    "                                              left_col=\"dummies_varName\",\n",
    "                                              right_col=\"dummies_varName\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_alpha = 0.05/len(variablesDict[\"pvalues\"])\n",
    "variablesDict[\"p_adj\"] = variablesDict[\"pvalues\"] / len(variablesDict[\"pvalues\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variablesDict['log_p'] = -np.log10(variablesDict['pvalues'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variablesDict = variablesDict.sort_index()\n",
    "variablesDict[\"group\"] = variablesDict.reset_index(level=1)[\"level_1\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Result visualisations: Manhattan plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manhattan plot is the classical results representation of a PheWAS analysis. It plots every each tested phenotypical variables on the X-axis, against its *-log(pvalue)* on the Y-axis. The horizontal line represent the adjusted significance level threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = variablesDict[\"pvalues\"].isna()\n",
    "df_results = variablesDict.loc[~mask,:].copy().replace([np.inf, -np.inf], np.nan)\n",
    "df_results[\"ind\"] = np.arange(1, len(df_results)+1)\n",
    "df_grouped = df_results.groupby(('group'))\n",
    "\n",
    "# print(df_grouped.head(10))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "colors = plt.get_cmap('Set1')\n",
    "x_labels = []\n",
    "x_labels_pos = []\n",
    "\n",
    "y_lims = (0,\n",
    "          df_results[\"log_p\"].max(skipna=True) + 20)\n",
    "threshold_top_values = df_results[\"log_p\"].sort_values(ascending=False)[0:6][-1]\n",
    "\n",
    "for num, (name, group) in enumerate(df_grouped):\n",
    "        group.plot(kind='scatter', x='ind', y='log_p',color=colors.colors[num % len(colors.colors)], ax=ax, s=20)\n",
    "        x_labels.append(name)\n",
    "        x_labels_pos.append((group['ind'].iloc[-1] - (group['ind'].iloc[-1] - group['ind'].iloc[0])/2)) # Set label in the middle\n",
    "        \n",
    "        pair_ind = 0 # To shift label which might overlap because to close\n",
    "        for n, row in group.iterrows():\n",
    "            if pair_ind %2 == 0:\n",
    "                shift = 1.1\n",
    "            else:\n",
    "                shift = -1.1\n",
    "            if row[\"log_p\"] > threshold_top_values:\n",
    "                ax.text(row['ind'] + 3, row[\"log_p\"] + 0.05 + shift, row[\"simplified_varName\"], rotation=0, alpha=1, size=8, color=\"black\")\n",
    "                pair_ind += 1\n",
    "                \n",
    "ax.set_xticks(x_labels_pos)\n",
    "ax.set_xticklabels(x_labels)\n",
    "ax.set_xlim([0, len(df_results) +1])\n",
    "ax.set_ylim(y_lims)\n",
    "ax.set_ylabel('-log(p-values)', style=\"italic\")\n",
    "ax.set_xlabel('Phenotypes')\n",
    "ax.axhline(y=-np.log10(adjusted_alpha), linestyle=\":\", color=\"black\")\n",
    "plt.xticks(fontsize = 8,rotation=90)\n",
    "plt.yticks(fontsize = 8)\n",
    "plt.title(\"Statistical association between studied allele and phenotypes\", \n",
    "          loc=\"center\",\n",
    "          style=\"oblique\", \n",
    "          fontsize = 20,\n",
    "         y=1)\n",
    "xticks = ax.xaxis.get_major_ticks()\n",
    "xticks[0].set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, it appears that most of the tested phenotypes covariates are above the adjusted threshold of significant association. However, it is not surprising at all, given the nature of our dependent variable: a lot of those variables are by nature tied directly to the COPD status."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code can be used directly with any other variable present in the variable Dictionary. It only need to change the `dependent_var_name` value."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "dbmi_jupyterhub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
