{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phenome-Wide analysis on COPDgene data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment pre-requisite\n",
    "- python 3.6 or later\n",
    "- pip\n",
    "- bash interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful to estimate execution time of the Notebook, see end of this file\n",
    "from datetime import datetime\n",
    "then = datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation of external dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "import PicSureHpdsLib\n",
    "import PicSureClient\n",
    "\n",
    "from python_lib.utils import get_multiIndex_variablesTable, get_dic_renaming_vars, match_dummies_to_varNames, joining_variablesTable_onCol\n",
    "from python_lib.HPDS_connection_manager import tokenManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NB: This Jupyter Notebook has been written using PIC-SURE API following versions:\\n- PicSureHpdsLib: 1.1.0\\n- PicSureClient: 0.1.0\")\n",
    "print(\"The PIC-SURE API libraries versions you've been downloading are:\\n- PicSureHpdsLib: {0}\\n- PicSureClient: {1}\".format(PicSureHpdsLib.__version__, PicSureClient.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas DataFrame display options\n",
    "pd.set_option(\"max.rows\", 435)\n",
    "\n",
    "# Matplotlib parameters options\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    " \n",
    "# Prints: [8.0, 6.0]\n",
    "fig_size[0] = 14\n",
    "fig_size[1] = 8\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "\n",
    "font = {'weight' : 'bold',\n",
    "        'size'   : 12}\n",
    "\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to a PIC-SURE network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PICSURE_network_URL = \"https://copdgene-dev.hms.harvard.edu/picsure/\"\n",
    "COPDGene_resource = \"b6ef7b1a-56f6-11e9-8958-0242c0a83007\"\n",
    "token_file = \"tokens/copd.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = tokenManager(token_file).get_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = PicSureClient.Client()\n",
    "connection = client.connect(PICSURE_network_URL, token, allowSelfSignedSSL=True)\n",
    "adapter = PicSureHpdsLib.Adapter(connection)\n",
    "resource = adapter.useResource(COPDGene_resource)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PheWAS analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving the relevant data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a nutshell, this PheWAS analysis consists of two main steps:\n",
    "- Running univariate tests again every phenotypes variable\n",
    "- Adjusting for multiple testing issue\n",
    "\n",
    "In this example, we will select every phenotype variables available in the Dictionary, except for the variables pertaining to the \"Sub-study ESP LungGO COPDGene\" category (very small and specific population as compared to the COPDGene one)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get Database variables dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_variablesDict = resource.dictionary().find().DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variablesDict = get_multiIndex_variablesTable(plain_variablesDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Select variables and query data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_pheno = variablesDict[\"HpdsDataType\"] == \"phenotypes\"\n",
    "mask_substudy = variablesDict.index.get_level_values(0) != \"Sub-study ESP LungGO COPDGene\"\n",
    "mask_vars = mask_pheno & mask_substudy\n",
    "selected_vars = variablesDict.loc[mask_vars, \"varName\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = resource.query()\n",
    "query.select().add(selected_vars)\n",
    "facts = query.getResultsDataFrame(selected_vars).set_index(\"Patient ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just check that our query runned the way intended by looking at the number of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{0} rows, {1} columns\".format(*facts.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data-management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting variables regarding their types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One important step in a PheWAS is to get the distinction between categorical and numerical variables. This distinction is straightforward using the variables dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_categories = variablesDict.loc[mask_vars, \"categorical\"] == True\n",
    "categorical_varnames = variablesDict.loc[mask_vars,:].loc[mask_categories, \"varName\"].tolist()\n",
    "continuous_varnames = variablesDict.loc[mask_vars,:].loc[~mask_categories, \"varName\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the independent variable to study\n",
    "Most of PheWAS use a genetic variant as the variable used to separate the population between cases and controls. But the population doesn't have to be dichotomized using a genetic variant, and any phenotypic variable could be used (see for example [*Neuraz et al.*, 2013](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003405)). \n",
    "\n",
    "Here we will use the presence or absence of a COPD diagnosis as the variable to dichotomize the population in our subsequent analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "independant_var_name = variablesDict.loc[variablesDict[\"simplified_varName\"] == \"00 Affection status\", \"varName\"].values[0]\n",
    "categorical_varnames.remove(independant_var_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we subset our population regarding the relevant values for the COPD diagnosis variable (i.e. keeping \"Case\" and \"Control\" individuals, thus discarding \"Other\", \"Control, Exclusionary Disease\", and null values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_independant_var_name = facts[independant_var_name].isin([\"Case\", \"Control\"])\n",
    "facts = facts.loc[mask_independant_var_name,:]\n",
    "print(\"Control: {0} individuals\\nCase: {1} individuals\".format(*facts[independant_var_name].value_counts().tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create dummy variables in order to be able to carry categorical univariate statistical tests, and we store their names in the dictionary alongside corresponding original variables in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "facts_dummies = pd.get_dummies(facts, columns=categorical_varnames, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_dummies_varNames = match_dummies_to_varNames(facts.columns,\n",
    "                                                      facts_dummies.columns,\n",
    "                                                      columns=[\"varName\", \"dummies_varName\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "variablesDict = joining_variablesTable_onCol(variablesDict,\n",
    "                                              matching_dummies_varNames,\n",
    "                                              left_col=\"varName\",\n",
    "                                              right_col=\"varName\",\n",
    "                                              overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variablesDict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate statistical tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To this point, each variable present in the facts_dummies dataset will be tested again the selected independent variable, (ie presence or absence of COPD). \n",
    "\n",
    "Two different association test will be carried out according to variables data types: \n",
    "- Mann-Whitney U test for continuous ones\n",
    "- Fisher exact test for categorical ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantitative variables: Mann-Whitney U test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = facts_dummies.groupby(independant_var_name) \n",
    "\n",
    "dic_mannwhitneyu = {}\n",
    "for var in continuous_varnames: \n",
    "    group1, group2 = [group[1].dropna() for group in grouped[var]]\n",
    "    try:\n",
    "        dic_mannwhitneyu[var] = stats.mannwhitneyu(group1, group2).pvalue\n",
    "    except ValueError:\n",
    "        dic_mannwhitneyu[var] = np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualitative variables: Fisher Exact test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_categorical_varnames = variablesDict.loc[variablesDict[\"varName\"].isin(categorical_varnames),:]\\\n",
    "[\"dummies_varName\"].values[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fisher test for categorical variables\n",
    "from tqdm import tqdm\n",
    "dic_fisher = {}\n",
    "try:\n",
    "    for var in tqdm(dummy_categorical_varnames, position=0, leave=True):\n",
    "        if type(var) != str:\n",
    "            print(\"skipping {0}\".format(var))\n",
    "            continue\n",
    "        elif var not in facts_dummies.columns:\n",
    "            print(\"skipping {0}, not in dataframe columns\".format(var))\n",
    "            continue        \n",
    "        crosstab = pd.crosstab(facts_dummies[var], facts_dummies[independant_var_name])\n",
    "        if crosstab.shape == (1,2):\n",
    "            dic_fisher[var] = np.NaN\n",
    "        else:\n",
    "            dic_fisher[var] = stats.fisher_exact(crosstab)[1]\n",
    "except AttributeError:\n",
    "    print(\"End of loop tqdm AttributeError catched\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Univariate tests distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([v for v in dic_mannwhitneyu.values()]).plot.hist(bins=30)\n",
    "plt.suptitle(\"Distribution of individual p-values for Mann-Whintey U test\",\n",
    "             weight=\"bold\",\n",
    "            fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([v for v in dic_fisher.values()]).plot.hist(bins=20)\n",
    "plt.suptitle(\"Distribution of individual p-values for Fisher association test\", \n",
    "             size=30,\n",
    "             weight=\"bold\",\n",
    "            fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple hypotheses testing correction: Bonferroni Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to handle the multiple comparison issue (increase in the probability to \"discover\" false statistical associations, because of the number of tests performed), we will use the Bonferroni correction method. Although many other multiple comparison exist, Bonferroni is the most straightforward to use, because it doesn't require assumptions about variables correlation. Other PheWAS analysis also use False Discovery Rate controlling procedures ([see](https://en.wikipedia.org/wiki/False_discovery_rate))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a nutshell, Bonferonni allows to calculate a corrected \"statistical significant threshold\" according to the number of test performed. Every p-value below this threshold will be deemed statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging pvalues from different tests\n",
    "dic_pvalues = {**dic_mannwhitneyu, **dic_fisher}\n",
    "df_pvalues = pd.DataFrame.from_dict(dic_pvalues, orient=\"index\", columns=[\"pvalues\"])\\\n",
    ".rename_axis(\"dummies_varName\")\\\n",
    ".reset_index(drop=False)\n",
    "\n",
    "# Adding pvalues results as a new column to variablesDict\n",
    "variablesDict = joining_variablesTable_onCol(variablesDict,\n",
    "                                              df_pvalues,\n",
    "                                              left_col=\"dummies_varName\",\n",
    "                                              right_col=\"dummies_varName\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_alpha = 0.05/len(variablesDict[\"pvalues\"])\n",
    "variablesDict[\"p_adj\"] = variablesDict[\"pvalues\"] / len(variablesDict[\"pvalues\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variablesDict[\"pvalues\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variablesDict['log_p'] = -np.log10(variablesDict['pvalues'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variablesDict = variablesDict.sort_index()\n",
    "variablesDict[\"group\"] = variablesDict.reset_index(level=1)[\"level_1\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manhattan plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classical synthetic data visualisation of a PheWAS analysis is the Manhattan plot, which plot each one of the tested phenotypes on the X-axis, against -log of pvalues on the Y axis. Usually a horizontal line is drawn to represent the corrected level of significance calculated using an adequate multiple hypothesis correction method (Bonferroni in our case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = variablesDict[\"pvalues\"].isna()\n",
    "df_results = variablesDict.loc[~mask,:].copy().replace([np.inf, -np.inf], np.nan)\n",
    "df_results[\"ind\"] = np.arange(1, len(df_results)+1)\n",
    "df_grouped = df_results.groupby(('group'))\n",
    "\n",
    "# print(df_grouped.head(10))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "colors = plt.get_cmap('Set1')\n",
    "x_labels = []\n",
    "x_labels_pos = []\n",
    "\n",
    "y_lims = (0,\n",
    "          df_results[\"log_p\"].max(skipna=True) + 20)\n",
    "threshold_top_values = df_results[\"log_p\"].sort_values(ascending=False)[0:6][-1]\n",
    "\n",
    "for num, (name, group) in enumerate(df_grouped):\n",
    "        group.plot(kind='scatter', x='ind', y='log_p',color=colors.colors[num % len(colors.colors)], ax=ax, s=20)\n",
    "        x_labels.append(name)\n",
    "        x_labels_pos.append((group['ind'].iloc[-1] - (group['ind'].iloc[-1] - group['ind'].iloc[0])/2)) # Set label in the middle\n",
    "        \n",
    "        pair_ind = 0 # To shift label which might overlap because to close\n",
    "        for n, row in group.iterrows():\n",
    "            if pair_ind %2 == 0:\n",
    "                shift = 1.1\n",
    "            else:\n",
    "                shift = -1.1\n",
    "            if row[\"log_p\"] > threshold_top_values:\n",
    "                ax.text(row['ind'] + 3, row[\"log_p\"] + 0.05 + shift, row[\"simplified_varName\"], rotation=0, alpha=1, size=8, color=\"black\")\n",
    "                pair_ind += 1\n",
    "                \n",
    "ax.set_xticks(x_labels_pos)\n",
    "ax.set_xticklabels(x_labels)\n",
    "ax.set_xlim([0, len(df_results) +1])\n",
    "ax.set_ylim(y_lims)\n",
    "ax.set_ylabel('-log(p-values)', style=\"italic\")\n",
    "ax.set_xlabel('Phenotypes')\n",
    "ax.axhline(y=-np.log10(adjusted_alpha), linestyle=\":\", color=\"black\")\n",
    "plt.xticks(fontsize = 8,rotation=90)\n",
    "plt.yticks(fontsize = 8)\n",
    "plt.title(\"Statistical association between studied allele and phenotypes\", \n",
    "          loc=\"center\",\n",
    "          style=\"oblique\", \n",
    "          fontsize = 20,\n",
    "         y=1)\n",
    "xticks = ax.xaxis.get_major_ticks()\n",
    "xticks[0].set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "elapsed = now - then\n",
    "print(elapsed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
