{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phenome-Wide analysis on TOPMed wide studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is an illustration example of how to use the python **PIC-SURE API** to select and query data from an HPDS-hosted database. It takes as use-case a simple PheWAS analysis. This notebook is intentionally straightforward, and explanation provided are only aimed at guiding through the PheWAS analysis pipeline. For a more step-by-step introduction to the python PIC-SURE API, see the `python_PICSURE-API_101_PheWAS_example.ipynb` Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before running this notebook, please be sure to get an user-specific security token. For more information on how to proceed, see the `HPDS_connection.ipynb` notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System requirements\n",
    "- Python 3.6 or later\n",
    "- pip & bash interpreter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation of external dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/hms-dbmi/pic-sure-python-adapter-hpds.git (from -r requirements.txt (line 7))\n",
      "  Cloning https://github.com/hms-dbmi/pic-sure-python-adapter-hpds.git to /private/var/folders/hm/wn0bpy0j7vl2q9gqnhhccpph0000gn/T/pip-req-build-f_x42w1q\n",
      "  Running command git clone -q https://github.com/hms-dbmi/pic-sure-python-adapter-hpds.git /private/var/folders/hm/wn0bpy0j7vl2q9gqnhhccpph0000gn/T/pip-req-build-f_x42w1q\n",
      "Requirement already satisfied (use --upgrade to upgrade): PicSureHpdsLib==0.9.0 from git+https://github.com/hms-dbmi/pic-sure-python-adapter-hpds.git in /Users/Arnaud/miniconda3/envs/dbmi_jupyterhub/lib/python3.6/site-packages (from -r requirements.txt (line 7))\n",
      "Collecting git+https://github.com/hms-dbmi/pic-sure-python-client.git (from -r requirements.txt (line 8))\n",
      "  Cloning https://github.com/hms-dbmi/pic-sure-python-client.git to /private/var/folders/hm/wn0bpy0j7vl2q9gqnhhccpph0000gn/T/pip-req-build-x5f4r4y0\n",
      "  Running command git clone -q https://github.com/hms-dbmi/pic-sure-python-client.git /private/var/folders/hm/wn0bpy0j7vl2q9gqnhhccpph0000gn/T/pip-req-build-x5f4r4y0\n",
      "Requirement already satisfied (use --upgrade to upgrade): PicSureClient==0.1.0 from git+https://github.com/hms-dbmi/pic-sure-python-client.git in /Users/Arnaud/miniconda3/envs/dbmi_jupyterhub/lib/python3.6/site-packages (from -r requirements.txt (line 8))\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/Arnaud/miniconda3/envs/dbmi_jupyterhub/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (1.17.4)\n",
      "Requirement already satisfied: matplotlib>=3.1.1 in /Users/Arnaud/miniconda3/envs/dbmi_jupyterhub/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (3.1.2)\n",
      "Requirement already satisfied: pandas>=0.25.3 in /Users/Arnaud/miniconda3/envs/dbmi_jupyterhub/lib/python3.6/site-packages (from -r requirements.txt (line 3)) (0.25.3)\n",
      "Requirement already satisfied: scipy>=1.3.1 in /Users/Arnaud/miniconda3/envs/dbmi_jupyterhub/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (1.3.3)\n",
      "Requirement already satisfied: tqdm>=4.38.0 in /Users/Arnaud/miniconda3/envs/dbmi_jupyterhub/lib/python3.6/site-packages (from -r requirements.txt (line 5)) (4.39.0)\n",
      "Requirement already satisfied: statsmodels>=0.10.2 in /Users/Arnaud/miniconda3/envs/dbmi_jupyterhub/lib/python3.6/site-packages (from -r requirements.txt (line 6)) (0.10.2)\n",
      "Requirement already satisfied: httplib2 in /Users/Arnaud/miniconda3/envs/dbmi_jupyterhub/lib/python3.6/site-packages (from PicSureHpdsLib==0.9.0->-r requirements.txt (line 7)) (0.14.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/Arnaud/miniconda3/envs/dbmi_jupyterhub/lib/python3.6/site-packages (from matplotlib>=3.1.1->-r requirements.txt (line 2)) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/Arnaud/miniconda3/envs/dbmi_jupyterhub/lib/python3.6/site-packages (from matplotlib>=3.1.1->-r requirements.txt (line 2)) (2.4.5)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/Arnaud/miniconda3/envs/dbmi_jupyterhub/lib/python3.6/site-packages (from matplotlib>=3.1.1->-r requirements.txt (line 2)) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/Arnaud/miniconda3/envs/dbmi_jupyterhub/lib/python3.6/site-packages (from matplotlib>=3.1.1->-r requirements.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/Arnaud/miniconda3/envs/dbmi_jupyterhub/lib/python3.6/site-packages (from pandas>=0.25.3->-r requirements.txt (line 3)) (2019.3)\n",
      "Requirement already satisfied: patsy>=0.4.0 in /Users/Arnaud/miniconda3/envs/dbmi_jupyterhub/lib/python3.6/site-packages (from statsmodels>=0.10.2->-r requirements.txt (line 6)) (0.5.1)\n",
      "Requirement already satisfied: six in /Users/Arnaud/miniconda3/envs/dbmi_jupyterhub/lib/python3.6/site-packages (from cycler>=0.10->matplotlib>=3.1.1->-r requirements.txt (line 2)) (1.13.0)\n",
      "Requirement already satisfied: setuptools in /Users/Arnaud/miniconda3/envs/dbmi_jupyterhub/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib>=3.1.1->-r requirements.txt (line 2)) (41.6.0.post20191030)\n",
      "Building wheels for collected packages: PicSureHpdsLib, PicSureClient\n",
      "  Building wheel for PicSureHpdsLib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for PicSureHpdsLib: filename=PicSureHpdsLib-0.9.0-py2.py3-none-any.whl size=17135 sha256=ac51256bd0120139cd1f18e1f9a73ca8fcc3106803ed37bdfed16d86ba1fe088\n",
      "  Stored in directory: /private/var/folders/hm/wn0bpy0j7vl2q9gqnhhccpph0000gn/T/pip-ephem-wheel-cache-l0_53sn_/wheels/6c/ac/12/4d142709d83e0bdd96c661e183f2dcbb0e03f90e98e5ac256e\n",
      "  Building wheel for PicSureClient (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for PicSureClient: filename=PicSureClient-0.1.0-py2.py3-none-any.whl size=8579 sha256=959b9ed6e7390a131e1ef2da31f3c23f32898fa69fc14e867ba90385bfd78c8f\n",
      "  Stored in directory: /private/var/folders/hm/wn0bpy0j7vl2q9gqnhhccpph0000gn/T/pip-ephem-wheel-cache-l0_53sn_/wheels/b4/c1/d9/744d4e1c1ba5f0c5d847deba1a7c8f96f47d4b36c610dda114\n",
      "Successfully built PicSureHpdsLib PicSureClient\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "import PicSureHpdsLib\n",
    "import PicSureClient\n",
    "\n",
    "from python_lib.utils import get_multiIndex_variablesDict, get_dic_renaming_vars, match_dummies_to_varNames, joining_variablesDict_onCol\n",
    "from python_lib.HPDS_connection_manager import tokenManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NB: This Jupyter Notebook has been written using PIC-SURE API following versions:\\n- PicSureHpdsLib: 1.1.0\\n- PicSureClient: 0.1.0\")\n",
    "print(\"The PIC-SURE API libraries versions you've been downloading are:\\n- PicSureHpdsLib: {0}\\n- PicSureClient: {1}\".format(PicSureHpdsLib.__version__, PicSureClient.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas DataFrame display options\n",
    "pd.set_option(\"max.rows\", 435)\n",
    "\n",
    "# Matplotlib display parameters\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 14\n",
    "fig_size[1] = 8\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "font = {'weight' : 'bold',\n",
    "        'size'   : 12}\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to a PIC-SURE network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PICSURE_network_URL = \"https://biodatacatalyst.integration.hms.harvard.edu/picsure\"\n",
    "resource_id = \"02e23f52-f354-4e8b-992c-d37c8b9ba140\"\n",
    "token_file = \"token.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = tokenManager(token_file).get_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = PicSureClient.Client()\n",
    "connection = client.connect(PICSURE_network_URL, token, allowSelfSignedSSL=True)\n",
    "adapter = PicSureHpdsLib.Adapter(connection)\n",
    "resource = adapter.useResource(resource_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PheWAS analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a nutshell, this PheWAS analysis follows those following steps:\n",
    "- Retrieving the variables dictionary, using the PIC-SURE API dedicated methods\n",
    "- From the info provided by the dictionary, retrieving the desired variables and individuals in an exploitable format through PIC-SURE API calls\n",
    "- Data management\n",
    "- Running univariate tests against every phenotypes variable\n",
    "- Accounting for multiple hypotheses testing issue\n",
    "- Plotting the results\n",
    "\n",
    "\n",
    "This analysis is conducted using individuals enrolled in the COPDGene Study. Overall goal of this cohort is to detect underlying genetic factors to develop Chronic Obstructive Pulmonary Disease (COPD), and currently includes more than 10,000 individuals ([more information on COPDGene Study](http://www.copdgene.org))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Retrieving variables dictionary from HPDS Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving variables dictionary only for the COPDGene study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_variablesDict = resource.dictionary().find(\"Genetic Epidemiology of COPD (COPDGene)\").DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variablesDict = get_multiIndex_variablesDict(plain_variablesDict)\n",
    "variablesDict.iloc[10:20,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Selecting variables and retrieving data from the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subseting to keep only the phenotypical variables + the \"affection status\", that will be used as the dependent variable for this illustration use-case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_pheno = variablesDict.index.get_level_values(1) == 'Subject Phenotype'\n",
    "mask_status = variablesDict.index.get_level_values(2) == 'Affection status'\n",
    "mask_vars = mask_pheno | mask_status\n",
    "variablesDict = variablesDict.loc[mask_vars,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_vars = variablesDict.loc[:, \"varName\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(selected_vars[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = resource.query()\n",
    "query.select().add(selected_vars[:1000])\n",
    "facts = query.getResultsDataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_var = variablesDict.loc[variablesDict.index.get_level_values(2) == 'Affection status', \"varName\"]\n",
    "facts = facts.dropna(subset=status_var)\\\n",
    ".set_index(\"Patient ID\")\n",
    "mask_to_drop = variablesDict[\"simplified_varName\"]\\\n",
    ".isin([\"Dbgap_id\", \"De-identified site code\", \"A1AD: phenotype/genotype\"])\n",
    "variablesDict = variablesDict.loc[~mask_to_drop, :]\n",
    "var_to_keep = variablesDict.loc[:, \"varName\"]\n",
    "facts = facts.loc[:, var_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{0} rows, {1} columns\".format(*facts.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a sample of our dataset, one row per patient and one column par variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data-management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting variables regarding their types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One important step in a PheWAS is to get the distinction between categorical and numerical variables. This distinction is straightforward using the variables dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_categories = variablesDict.loc[:, \"categorical\"] == True\n",
    "categorical_varnames = variablesDict.loc[mask_categories, \"varName\"].tolist()\n",
    "continuous_varnames = variablesDict.loc[~mask_categories, \"varName\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the dependent variable to study\n",
    "Most of PheWAS use a genetic variant as the variable used to separate the population between cases and controls. However the population doesn't have to be dichotomized using a genetic variant, and any phenotypic variable could be used to run a PheWAS analysis (see for example [*Neuraz et al.*, 2013](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003405)). \n",
    "\n",
    "Here we will use the **COPD status** as the case-control variable to dichotomize the population in our analysis, and keep only the population subset containing relevant values for the COPD status (i.e. keeping \"Case\" and \"Control\" individuals, thus discarding \"Other\", \"Control, Exclusionary Disease\", and null values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent_var_name = variablesDict.loc[variablesDict[\"simplified_varName\"] == \"Affection status\", \"varName\"].values[0]\n",
    "categorical_varnames.remove(dependent_var_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_dependent_var_name = facts[dependent_var_name].isin([\"Case\", \"Control\"])\n",
    "facts = facts.loc[mask_dependent_var_name,:]\\\n",
    "             .astype({dependent_var_name: \"category\"})\n",
    "print(\"Control: {0} individuals\\nCase: {1} individuals\".format(*facts[dependent_var_name].value_counts().tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Univariate statistical tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To this point, each variable present in the `facts_dummies` dataset will be tested again the selected dependent variable, (ie presence or absence of COPD). \n",
    "\n",
    "Two different association test will be carried out according to variables data types: \n",
    "- Mann-Whitney U test for continuous ones\n",
    "- Fisher exact test for categorical ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLR result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.discrete.discrete_model import Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_varNames = variablesDict[\"varName\"].tolist()\n",
    "independent_varNames.remove(dependent_var_name)\n",
    "dependent_var = facts[dependent_var_name].astype(\"category\").cat.codes\n",
    "dic_pvalues = {}\n",
    "simple_index_variablesDict = variablesDict.set_index(\"varName\", drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import LinAlgError\n",
    "from statsmodels.tools.sm_exceptions import PerfectSeparationError\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for independent_varName in tqdm(independent_varNames, position=0, leave=True):\n",
    "    matrix = facts.loc[:, [dependent_var_name, independent_varName]]\\\n",
    "                  .dropna(how=\"any\")\n",
    "    if matrix.shape[0] == 0:\n",
    "        dic_pvalues[independent_varName] = np.NaN\n",
    "        continue\n",
    "    if simple_index_variablesDict.loc[independent_varName, \"categorical\"]:\n",
    "        matrix = pd.get_dummies(matrix,\n",
    "                                columns=[independent_varName],\n",
    "                                drop_first=False)\\\n",
    "                    .iloc[:, 0:-1]\n",
    "    dependent_var = matrix[dependent_var_name].cat.codes\n",
    "    independent_var = matrix.drop(dependent_var_name, axis=1)\\\n",
    "                            .assign(intercept = 1)\n",
    "    model = Logit(dependent_var, independent_var)\n",
    "    try:\n",
    "        results = model.fit(disp=0)\n",
    "        dic_pvalues[independent_varName] = results.llr_pvalue\n",
    "    except (LinAlgError, PerfectSeparationError) as e:\n",
    "        dic_pvalues[independent_varName] = np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### p-values distribution (univariate tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([v for v in dic_pvalues.values()]).plot.hist(bins=30)\n",
    "plt.suptitle(\"Distribution of individual p-values\",\n",
    "             weight=\"bold\",\n",
    "            fontsize=15)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.Series([v for v in dic_fisher.values()]).plot.hist(bins=20)\n",
    "plt.suptitle(\"Distribution of individual p-values for Fisher association test\", \n",
    "             size=30,\n",
    "             weight=\"bold\",\n",
    "            fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Multiple hypotheses testing correction: Bonferroni Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to handle the multiple testing problem (increase in the probability to \"discover\" false statistical associations), we will use the Bonferroni correction method. Although many other multiple comparisons exist, Bonferroni is the most straightforward to use, because it doesn't require assumptions about variables correlation. Other PheWAS analysis also use False Discovery Rate controlling procedures ([see](https://en.wikipedia.org/wiki/False_discovery_rate))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a nutshell, Bonferonni allows to calculate a corrected \"statistical significant threshold\" according to the number of test performed. Every p-value below this threshold will be deemed statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Merging pvalues from different tests\n",
    "df_pvalues = pd.DataFrame.from_dict(dic_pvalues, orient=\"index\", columns=[\"pvalues\"])\\\n",
    ".rename_axis(\"varName\")\\\n",
    ".reset_index(drop=False)\n",
    "\n",
    "# Adding pvalues results as a new column to variablesDict\n",
    "variablesDict = joining_variablesDict_onCol(variablesDict,\n",
    "                                              df_pvalues,\n",
    "                                              left_col=\"varName\",\n",
    "                                              right_col=\"varName\")\n",
    "\n",
    "adjusted_alpha = 0.05/len(variablesDict[\"pvalues\"])\n",
    "variablesDict[\"p_adj\"] = variablesDict[\"pvalues\"] / len(variablesDict[\"pvalues\"])\n",
    "variablesDict['log_p'] = -np.log10(variablesDict['pvalues'])\n",
    "variablesDict = variablesDict.sort_index()\n",
    "variablesDict[\"group\"] = variablesDict.reset_index(level=2)[\"level_2\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Bonferonni adjusted significance threshold: {0:.2E}\".format(adjusted_alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Result visualisations: Manhattan plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manhattan plot is the classical way to plot the results of a PheWAS analysis. It plots every tested phenotypical variables on the X-axis, against its *-log(pvalue)* on the Y-axis. The horizontal line represent the adjusted significance level threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = variablesDict[\"pvalues\"].isna()\n",
    "df_results = variablesDict.loc[~mask,:].copy().replace([np.inf, -np.inf], np.nan)\n",
    "df_results = df_results.loc[~df_results[\"log_p\"].isna().values,:]\n",
    "\n",
    "#### Specific adjustment to make this specific plot looks nicer\n",
    "####### to adapt when changing data or dependent variable\n",
    "df_results = df_results.replace({\"TLC\": \"Spirometry\",\n",
    "                                 \"New Gold Classification\": \"Quantitative Analysis\", \n",
    "                  \"Other\": \"Demographics\"})\n",
    "group_order={'6MinWalk': 0,\n",
    " 'CT Acquisition Parameters': 1,\n",
    " 'CT Assessment Scoresheet': 2,\n",
    " 'Demographics and Physical Characteristics': 3,\n",
    " 'Eligibility Form': 10,\n",
    " 'Longitudinal Analysis': 5,\n",
    " 'Medical History': 4,\n",
    " 'Medication History': 13,\n",
    " 'Quantitative Analysis': 9,\n",
    " 'Respiratory Disease': 6,\n",
    " 'SF-36 Health Survey': 11,\n",
    " 'Sociodemography and Administration': 12,\n",
    " 'Spirometry': 7,\n",
    " 'VIDA': 15}\n",
    "df_results[\"group_order\"] = df_results[\"group\"].replace(group_order)\n",
    "df_results = df_results.sort_values(\"group_order\", ascending=True)\n",
    "df_results[\"simplified_varName\"] = df_results[\"simplified_varName\"].str.replace(\"[0-9]+[A-z]*\", \"\").to_frame()\n",
    "###\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "colors = plt.get_cmap('Set1')\n",
    "x_labels = []\n",
    "x_labels_pos = []\n",
    "\n",
    "y_lims = (0, df_results[\"log_p\"].max(skipna=True) + 50)\n",
    "threshold_top_values = df_results[\"log_p\"].sort_values(ascending=False)[0:6][-1]\n",
    "\n",
    "df_results[\"ind\"] = np.arange(1, len(df_results)+1)\n",
    "df_grouped = df_results.groupby(('group'))\n",
    "for num, (name, group) in enumerate(df_grouped):\n",
    "    group.plot(kind='scatter', x='ind', y='log_p',color=colors.colors[num % len(colors.colors)], ax=ax, s=20)\n",
    "    x_labels.append(name)\n",
    "    x_labels_pos.append((group['ind'].iloc[-1] - (group['ind'].iloc[-1] - group['ind'].iloc[0])/2)) # Set label in the middle\n",
    "    for n, row in group.iterrows():\n",
    "        if row[\"log_p\"] > threshold_top_values:\n",
    "            ax.text(row['ind'] + 3, row[\"log_p\"] + 0.05, row[\"simplified_varName\"], rotation=0, alpha=1, size=8, color=\"black\")\n",
    "                \n",
    "ax.set_xticks(x_labels_pos)\n",
    "ax.set_xticklabels(x_labels)\n",
    "ax.set_xlim([0, len(df_results) +1])\n",
    "ax.set_ylim(y_lims)\n",
    "ax.set_ylabel('-log(p-values)', style=\"italic\")\n",
    "ax.set_xlabel('Phenotypes', fontsize=15)\n",
    "ax.axhline(y=-np.log10(adjusted_alpha), linestyle=\":\", color=\"black\", label=\"Adjusted Threshold\")\n",
    "plt.xticks(fontsize = 9,rotation=90)\n",
    "plt.yticks(fontsize = 8)\n",
    "plt.title(\"Statistical Association Between COPD Status and Phenotypes\", \n",
    "          loc=\"center\",\n",
    "          style=\"oblique\", \n",
    "          fontsize = 20,\n",
    "         y=1)\n",
    "xticks = ax.xaxis.get_major_ticks()\n",
    "xticks[0].set_visible(False)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "plt.legend(handles = handles, labels = labels, loc = \"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, it appears that most of the tested phenotypes covariates are above the adjusted threshold of significant association. However, it is not surprising at all, given the nature of our dependent variable: a lot of those variables are by nature tied directly to the COPD status."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code can be used directly with any other variable present in the variable Dictionary. It only need to change the `dependent_var_name` value."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "dbmi_jupyterhub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
